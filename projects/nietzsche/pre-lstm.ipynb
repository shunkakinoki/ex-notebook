{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nietzsche.txt: 606kB [00:02, 294kB/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "text = open(f'{PATH}nietzsche.txt').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nietzsche.txt\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH='data/nietzsche/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
    "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
    "# - val/val.txt (last 20% of nietzsche.txt)\n",
    "os.makedirs(f'{TRN}', exist_ok=True)\n",
    "os.makedirs(f'{VAL}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn=\"\"\n",
    "val=\"\"\n",
    "for i, character in enumerate(text):\n",
    "    if i < len(text)*0.8:\n",
    "        trn = trn + character\n",
    "    else:\n",
    "        val = val + character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{TRN}trn.txt\",\"w\") \n",
    "file.write(trn)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{VAL}val.txt\",\"w\") \n",
    "file.write(val)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(922, 55, 1, 472944)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4761fadd534f49975cbc0331005c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.841173   1.764152  \n",
      "    1      1.726264   1.672768  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.67277])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebdf0079c1140d991b358d848f6bba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.556026   1.512069  \n",
      "    1      1.586439   1.533572  \n",
      "    2      1.475795   1.448702  \n",
      "    3      1.610676   1.561134  \n",
      "    4      1.52845    1.497698  \n",
      "    5      1.442953   1.430195  \n",
      "    6      1.390016   1.395813  \n",
      "    7      1.582066   1.550931  \n",
      "    8      1.535927   1.506746  \n",
      "    9      1.518942   1.494451  \n",
      "    10     1.466848   1.461279  \n",
      "    11     1.428705   1.426923  \n",
      "    12     1.383774   1.395188  \n",
      "    13     1.334992   1.366776  \n",
      "    14     1.311327   1.353291  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.35329])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f864c0630f2540aeb3dfc78767b8ec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.30778    1.352004  \n",
      "    1      1.301252   1.350355  \n",
      "    2      1.302714   1.349592  \n",
      "    3      1.296127   1.348195  \n",
      "    4      1.291974   1.346316  \n",
      "    5      1.287176   1.344816  \n",
      "    6      1.284781   1.343822  \n",
      "    7      1.28707    1.342817  \n",
      "    8      1.283692   1.340758  \n",
      "    9      1.274088   1.338131  \n",
      "    10     1.264213   1.337362  \n",
      "    11     1.261129   1.336304  \n",
      "    12     1.261063   1.335735  \n",
      "    13     1.259446   1.335039  \n",
      "    14     1.257951   1.334479  \n",
      "    15     1.254081   1.33501   \n",
      "    16     1.256233   1.333435  \n",
      "    17     1.252665   1.332503  \n",
      "    18     1.248097   1.332752  \n",
      "    19     1.239251   1.330847  \n",
      "    20     1.237829   1.330884  \n",
      "    21     1.233665   1.330479  \n",
      "    22     1.219488   1.330095  \n",
      "    23     1.220874   1.330426  \n",
      "    24     1.212397   1.330599  \n",
      "    25     1.209258   1.33003   \n",
      "    26     1.208891   1.330065  \n",
      "    27     1.205595   1.330224  \n",
      "    28     1.201558   1.330312  \n",
      "    29     1.202786   1.33011   \n",
      "    30     1.19671    1.329872  \n",
      "    31     1.195315   1.329865  \n",
      "    32     1.211727   1.330501  \n",
      "    33     1.206344   1.329445  \n",
      "    34     1.200637   1.330984  \n",
      "    35     1.195647   1.33216   \n",
      "    36     1.183767   1.332172  \n",
      "    37     1.179869   1.33393   \n",
      "    38     1.178905   1.334954  \n",
      "    39     1.170271   1.335807  \n",
      "    40     1.159742   1.336413  \n",
      "    41     1.155492   1.337156  \n",
      "    42     1.147948   1.339353  \n",
      "    43     1.142333   1.340399  \n",
      "    44     1.131866   1.341996  \n",
      "    45     1.124533   1.34351   \n",
      "    46     1.122418   1.345252  \n",
      "    47     1.120681   1.346824  \n",
      "    48     1.117078   1.347503  \n",
      "    49     1.108542   1.348738  \n",
      "    50     1.100042   1.350163  \n",
      "    51     1.097627   1.351111  \n",
      "    52     1.090255   1.352094  \n",
      "    53     1.092484   1.353125  \n",
      "    54     1.091712   1.354533  \n",
      "    55     1.086984   1.355402  \n",
      "    56     1.07564    1.355468  \n",
      "    57     1.074846   1.35616   \n",
      "    58     1.072419   1.356765  \n",
      "    59     1.069534   1.356995  \n",
      "    60     1.075136   1.356807  \n",
      "    61     1.077175   1.356849  \n",
      "    62     1.07947    1.356794  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.35679])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those except--and irrotroussang--how much mysterious?--very mexistemporarily, the fights like at whonow these at one things--derider. and in itself, as weak, slanger, does its attemment--the dispart from que contain. everything that which metaphysic of truths? the restandfingers or utthings when heart flourish genius, impulse in him. _and i salvis and love. justas itmaster and disgust be from the leas\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cc08dd732a4e08ae567d4688bca7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      1.075272   1.356896  \n",
      "    1      1.075038   1.356848  \n",
      "    2      1.069497   1.356822  \n",
      "    3      1.078831   1.356914  \n",
      "    4      1.079869   1.357034  \n",
      "    5      1.07352    1.356947  \n",
      "    6      1.075501   1.356982  \n",
      "    7      1.073789   1.357379  \n",
      "    8      1.074271   1.35722   \n",
      "    9      1.074571   1.356851  \n",
      "    10     1.079309   1.357351  \n",
      "    11     1.072891   1.357408  \n",
      "    12     1.0768     1.357503  \n",
      "    13     1.074071   1.357369  \n",
      "    14     1.075713   1.357184  \n",
      "    15     1.072792   1.357689  \n",
      "    16     1.077057   1.357697  \n",
      "    17     1.070722   1.358103  \n",
      "    18     1.075098   1.358001  \n",
      "    19     1.072626   1.358112  \n",
      "    20     1.070286   1.357969  \n",
      "    21     1.071924   1.358212  \n",
      "    22     1.06788    1.358041  \n",
      "    23     1.076886   1.358287  \n",
      "    24     1.073448   1.357998  \n",
      "    25     1.074117   1.358291  \n",
      "    26     1.071992   1.358329  \n",
      "    27     1.072054   1.358355  \n",
      "    28     1.062552   1.358282  \n",
      "    29     1.074273   1.358289  \n",
      "    30     1.074074   1.358255  \n",
      "    31     1.072896   1.358299  \n",
      "    32     1.073023   1.358437  \n",
      "    33     1.074881   1.358342  \n",
      "    34     1.068772   1.358662  \n",
      "    35     1.074758   1.358755  \n",
      "    36     1.074556   1.35881   \n",
      "    37     1.069656   1.358987  \n",
      "    38     1.068262   1.358936  \n",
      "    39     1.074031   1.358882  \n",
      "    40     1.066676   1.358871  \n",
      "    41     1.075118   1.358893  \n",
      "    42     1.07515    1.358895  \n",
      "    43     1.070307   1.359402  \n",
      "    44     1.069136   1.359138  \n",
      "    45     1.073951   1.359221  \n",
      "    46     1.070788   1.359168  \n",
      "    47     1.069493   1.359445  \n",
      "    48     1.070158   1.359395  \n",
      "    49     1.071144   1.359437  \n",
      "    50     1.062166   1.3595    \n",
      "    51     1.070009   1.359446  \n",
      "    52     1.069456   1.359488  \n",
      "    53     1.066537   1.359409  \n",
      "    54     1.069447   1.359625  \n",
      "    55     1.065734   1.359598  \n",
      "    56     1.064857   1.35947   \n",
      "    57     1.073979   1.35959   \n",
      "    58     1.067016   1.359612  \n",
      "    59     1.0655     1.359208  \n",
      "    60     1.069438   1.359594  \n",
      "    61     1.068925   1.359599  \n",
      "    62     1.068736   1.359518  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.35952])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/first_nietzsche')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/notebooks/data/nietzsche/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/notebooks/data/nietzsche/cyc_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(file_path, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(m, \"second_nietzsche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those wayin fraid to shape, among the out, by a state and feminine.;: julad, and in your i skepticism andcanness, from the back of point to victry betrays them--when the germans someof path of city of itself they are so ners have arrived--a singular) horsesthe the age alas, requiring-and instinctions, indeed thegenerations that the sharps likewisselywith roce--were age?--!808.242. \"be attack (nake, co\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
